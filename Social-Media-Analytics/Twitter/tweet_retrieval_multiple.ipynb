{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from google.cloud import language\n",
    "import google.cloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import operator\n",
    "import facebook\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Create client instance for Google Natural Language API\n",
    "client = language.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter Credentials\n",
    "\n",
    "#Authentication Credentials\n",
    "consumer_key = 'consumer_key'\n",
    "consumer_secret = 'consumer_secret'\n",
    "\n",
    "access_token = 'access_token'\n",
    "access_token_secret = 'access_token_secret'\n",
    "\n",
    "#Twitter API Authorization\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_handles = {'RDUairport' : 'RDU',\n",
    "                'rduceo' : 'RDU',\n",
    "                'CLTAirport' : 'Charlotte',\n",
    "                'AUStinAirport' : 'Austin',\n",
    "                'Fly_Nashville' : 'Nashville',\n",
    "                'sdfariport' : 'Louisville',\n",
    "                'flylouisville' : 'Louisville',\n",
    "                'INDairport' : 'Indianapolis',\n",
    "                'SanDiegoAirport' : 'San_Diego',\n",
    "                'flypdx' : 'Portland',\n",
    "                'atlairport' : 'Atlanta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(columns = ['date', 'time', 'location', 'handle', 'brand',\\\n",
    "                                    'tweet', 'posting_user', 'sentiment', 'magnitude', 'entities',\\\n",
    "                                    'entity_salience', 'geolocation', 'place', 'coordinates',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-02-26',\n",
       " '2017-02-27',\n",
       " '2017-02-28',\n",
       " '2017-03-01',\n",
       " '2017-03-02',\n",
       " '2017-03-03',\n",
       " '2017-03-04',\n",
       " '2017-03-05',\n",
       " '2017-03-06',\n",
       " '2017-03-07']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get date list for last 10 days\n",
    "\n",
    "date_list = []\n",
    "start_date = (datetime.datetime.now() + datetime.timedelta(-10))\n",
    "for i in range(10): \n",
    "    start_date += datetime.timedelta(days=1)\n",
    "    date_str = start_date.strftime('%Y-%m-%d')\n",
    "    date_list.append(date_str)\n",
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-02-26'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since_date = (datetime.datetime.now() + datetime.timedelta(-9))\n",
    "since = since_date.strftime('%Y-%m-%d')\n",
    "since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetDict = {}\n",
    "\n",
    "# Understanding geolocation\n",
    "geoDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [00:12<00:10,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [04:11<00:00, 19.63s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Itereate through large handles\n",
    "for handle_iter in tqdm.tqdm(main_handles.items()):\n",
    "    \n",
    "    handle = handle_iter[0]\n",
    "    brand = handle_iter[1]\n",
    "            \n",
    "    tempTweetList = []\n",
    "\n",
    "    # Get tweets for one handle, on one day\n",
    "    for tweet in tweepy.Cursor(api.search, q = '@' + handle, since = since, \\\n",
    "                               lang ='en', wait_on_rate_limit = True, \\\n",
    "                               wait_on_rate_limit_notify = True).items():\n",
    "        tempTweetList.append(tweet)\n",
    "    tweetDict['tweets_' + handle] = tempTweetList\n",
    "\n",
    "    tempTweetDateList = []\n",
    "    tempTweetTimeList = []\n",
    "    tempTweetLocationList = []\n",
    "    tempTweetGeoList = []\n",
    "    tempTweetPlaceList = []\n",
    "    tempTweetCoordList = []\n",
    "    tempTweetTextList = []\n",
    "    tempTweetUserList = []\n",
    "    tempTweetPostIDList = []\n",
    "    tempTweetHandleList = []\n",
    "\n",
    "    # Extract data from tweet objects\n",
    "    for tweet_obj in tweetDict['tweets_' + handle]:\n",
    "        tempTweetDateList.append(datetime.datetime.strftime(tweet_obj.created_at, '%Y-%m-%d'))\n",
    "        tempTweetTimeList.append(str((tweet_obj.created_at).time()))\n",
    "        tempTweetLocationList.append(tweet_obj.user.location)\n",
    "        tempTweetGeoList.append(tweet_obj.geo)\n",
    "        if tweet_obj.place:\n",
    "            tempTweetPlaceList.append(tweet_obj.place.bounding_box.coordinates[0])\n",
    "        else:\n",
    "            tempTweetPlaceList.append(None)\n",
    "        tempTweetCoordList.append(tweet_obj.coordinates)\n",
    "        tempTweetTextList.append(tweet_obj.text)\n",
    "        tempTweetUserList.append(tweet_obj.author.name)\n",
    "        tempTweetPostIDList.append(tweet_obj.id)\n",
    "        tempTweetHandleList.append('@' + handle)\n",
    "\n",
    "        # Understanding Geolocation\n",
    "        if tweet_obj.geo:\n",
    "            geoDict[('geo', tweet_obj.id)] = tweet_obj.geo\n",
    "        elif tweet_obj.place:\n",
    "            geoDict[('place', tweet_obj.id)] = tweet_obj.place\n",
    "        elif tweet_obj.coordinates:\n",
    "            geoDict[('coord', tweet_obj.id)] = tweet_obj.coordinates\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    temp_df = pd.DataFrame(columns = ['date', 'time', 'location', 'handle', 'brand',\\\n",
    "                                    'tweet', 'posting_user', 'sentiment', 'magnitude', 'entities',\\\n",
    "                                    'entity_salience', 'geolocation', 'place', 'coordinates',])\n",
    "    temp_df['date'] = tempTweetDateList\n",
    "    temp_df['time'] = tempTweetTimeList\n",
    "    temp_df['location'] = tempTweetLocationList\n",
    "    temp_df['handle'] = tempTweetHandleList\n",
    "    temp_df['brand'] = brand\n",
    "    temp_df['tweet'] = tempTweetTextList\n",
    "    temp_df['posting_user'] = tempTweetUserList\n",
    "    \n",
    "    temp_df['geolocation'] = tempTweetGeoList\n",
    "    temp_df['place'] = tempTweetPlaceList\n",
    "    temp_df['coordinates'] = tempTweetCoordList\n",
    "\n",
    "    df_tweets = pd.concat([df_tweets, temp_df])\n",
    "\n",
    "    df_tweets.to_csv('/Users/thays/Desktop/RDU_pitch/RDU_pitch_{0}_tweets.csv'.format(brand), encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'ECUAthletics'\n",
    "tempTweetList = []\n",
    "for ix, date_query in enumerate(date_list):    \n",
    "    since = date_query\n",
    "    if ix != len(date_list) - 1:\n",
    "        until = date_list[ix + 1]\n",
    "    else:\n",
    "        until = date_query\n",
    "        \n",
    "    for tweet in tweepy.Cursor(api.search, q = '@' + query, since = since, until = until,  \\\n",
    "                               wait_on_rate_limit = True, \\\n",
    "                               wait_on_rate_limit_notify = True).items():\n",
    "        tempTweetList.append(tweet)\n",
    "        print ('iteration')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
